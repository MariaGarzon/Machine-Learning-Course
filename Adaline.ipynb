{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa25854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb924e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  variety  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame with features, targets, and target names\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target_names'] = iris.target_names[iris.target]\n",
    "\n",
    "# Rename the 'target_names' column to 'variety'\n",
    "iris_df.rename(columns={'target_names': 'variety'}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f85566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for 'setosa' and 'virginica' species\n",
    "filtered_df = iris_df[iris_df['variety'].isin(['setosa', 'virginica'])]\n",
    "\n",
    "# Select the features and target\n",
    "X = filtered_df[['sepal length (cm)', 'petal width (cm)']]\n",
    "y = pd.factorize(filtered_df['variety'])[0] # Since the perceptron only intakes binary values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd12bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training data points: 70\n",
      "#Testing data points: 30\n",
      "Class labels: [0 1] (mapped from ['setosa' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('#Training data points: {}'.format(X_train.shape[0]))\n",
    "print('#Testing data points: {}'.format(X_test.shape[0]))\n",
    "print('Class labels: {} (mapped from {}'.format(np.unique(y), np.unique(filtered_df['variety'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7aa3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69182fa3",
   "metadata": {},
   "source": [
    "### Implementing Adaline\n",
    "\n",
    "Adaline uses an optimization technique, such as gradient descent, to minimize the cost function. Gradient descent iteratively adjusts the weights to find the minimum of the cost function. Adaline's weights are updated in a way that minimizes the mean squared error (MSE) or a similar cost function.\n",
    "\n",
    "Adaline uses a linear activation function that produces continuous-valued output. Instead of making binary decisions, Adaline computes a real-valued output for each sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57131a2b",
   "metadata": {},
   "source": [
    "The adaline batch gradient descent algorithm that is used below was obtained from: https://nthu-datalab.github.io/ml/labs/04-1_Perceptron_Adaline/04-1_Perceptron_Adaline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119cc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "        Passes over the training dataset.\n",
    "    random_state : int\n",
    "        The seed of the pseudo random number generator.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_ : list\n",
    "        Number of misclassifications in every epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like; shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like; shape = [n_samples]\n",
    "            Target values or labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1+X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            output = self.activation(X)\n",
    "            \n",
    "            # Cost function\n",
    "            error = (y - output)\n",
    "            cost = (error**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "            \n",
    "            # Update rule\n",
    "            self.w_[1:] += self.eta * X.T.dot(error)\n",
    "            self.w_[0] += self.eta * error.sum()\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1617143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 17\n",
      "Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "ada = AdalineGD(n_iter=20, eta=0.01)\n",
    "ada.fit(X_train_std, y_train)\n",
    "\n",
    "# testing accuracy\n",
    "y_pred = ada.predict(X_test_std)\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361640c",
   "metadata": {},
   "source": [
    "ADA With 3 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8e5e9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training data points: 70\n",
      "#Testing data points: 30\n",
      "Class labels: [0 1] (mapped from ['setosa' 'virginica']\n",
      "Misclassified samples: 17\n",
      "Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "X2 = filtered_df[['sepal length (cm)', 'sepal width (cm)', 'petal width (cm)']]\n",
    "y = pd.factorize(filtered_df['variety'])[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print('#Training data points: {}'.format(X_train.shape[0]))\n",
    "print('#Testing data points: {}'.format(X_test.shape[0]))\n",
    "print('Class labels: {} (mapped from {}'.format(np.unique(y), np.unique(filtered_df['variety'])))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ada2 = AdalineGD(n_iter=20, eta=0.01)\n",
    "ada2.fit(X_train_std, y_train)\n",
    "\n",
    "# testing accuracy\n",
    "y_pred = ada2.predict(X_test_std)\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85cd491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Training data points: 70\n",
      "#Testing data points: 30\n",
      "Class labels: [0 1] (mapped from ['setosa' 'virginica']\n",
      "Misclassified samples: 30\n",
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "X3 = filtered_df[['sepal length (cm)', 'sepal width (cm)', 'petal width (cm)', \n",
    "                'petal length (cm)']]\n",
    "y = pd.factorize(filtered_df['variety'])[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print('#Training data points: {}'.format(X_train.shape[0]))\n",
    "print('#Testing data points: {}'.format(X_test.shape[0]))\n",
    "print('Class labels: {} (mapped from {}'.format(np.unique(y), np.unique(filtered_df['variety'])))\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "ada2 = AdalineGD(n_iter=20, eta=0.01)\n",
    "ada2.fit(X_train_std, y_train)\n",
    "\n",
    "# testing accuracy\n",
    "y_pred = ada2.predict(X_test_std)\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e427c2",
   "metadata": {},
   "source": [
    "In all cases, it appears that the AdalineGD model didn't perform well on this dataset. The accuracy is quite low, indicating that the model might not be suitable for this classification task. Additionally, for the 4-feature case, the accuracy dropped to 0%, suggesting that the model might not be able to find a suitable decision boundary for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade52157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
